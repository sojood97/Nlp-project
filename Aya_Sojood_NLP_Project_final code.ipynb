{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Papers -- Split Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "titles = []\n",
    "texts = []\n",
    "abstracts=[]\n",
    "\n",
    "#title = text_data[0]\n",
    "#abstract=text_data[1]\n",
    "#paper text=text_data[10:]\n",
    "\n",
    "\n",
    "def read_papers(path):\n",
    "     for dirname, categoryname, filenames in os.walk(path):\n",
    "            for filename in filenames:\n",
    "                if filename == 'README.TXT':\n",
    "                    filenames.remove(filename)\n",
    "                else:\n",
    "                    current_file = os.path.abspath(os.path.join(dirname, filename))\n",
    "                    open_file = open(current_file, 'r', encoding=\"utf16\",errors='ignore')\n",
    "                    text_data = open_file.read().split('\\n')\n",
    "                    text_data = list(filter(None, text_data))\n",
    "                    titles.append(text_data[0])\n",
    "                    abstracts.append(text_data[1])\n",
    "                    texts.append((dirname, filename, text_data[0],text_data[1], text_data[10:]))\n",
    "     df = pd.DataFrame(texts, columns=['Directory', 'FileName', 'Title','Summary', 'Text'])\n",
    "     df['Text'] = df.Text.astype(str)\n",
    "     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Directory</th>\n",
       "      <th>FileName</th>\n",
       "      <th>Title</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/sojood/Desktop/papers-text/Text Files/</td>\n",
       "      <td>1-s2.0-S2211381912001087-main.txt</td>\n",
       "      <td>Available online at www.sciencedirect.com</td>\n",
       "      <td>Many modern service systems rely on a network ...</td>\n",
       "      <td>['While the ROASWSN design decision is to sele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/sojood/Desktop/papers-text/Text Files/</td>\n",
       "      <td>1012.2609.txt</td>\n",
       "      <td>J OURNAL OF I NFORMATION S CIENCE AND E NGINEE...</td>\n",
       "      <td>Term weighting schemes often dominate the perf...</td>\n",
       "      <td>['*   This work was supported supported by the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/sojood/Desktop/papers-text/Text Files/</td>\n",
       "      <td>1207.1847v1.txt</td>\n",
       "      <td>The University of Sheﬃeld</td>\n",
       "      <td>The statistical methods derived and described ...</td>\n",
       "      <td>['Part 3.    Applications                     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/sojood/Desktop/papers-text/Text Files/</td>\n",
       "      <td>1209.3126v1.txt</td>\n",
       "      <td>Beyond Stemming and Lemmatization:</td>\n",
       "      <td>In Automatic Text Summarization, preprocessing...</td>\n",
       "      <td>['\\ufeff\\x0c', 'a heterogeneous set of documen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/sojood/Desktop/papers-text/Text Files/</td>\n",
       "      <td>1210.0852.txt</td>\n",
       "      <td>Detecting multiword phrases in mathematical te...</td>\n",
       "      <td>We present an approach for detecting multiword...</td>\n",
       "      <td>['•   locally symmetrical Finsler manifold(s) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:/Users/sojood/Desktop/papers-text/Text Files/</td>\n",
       "      <td>1305.6143.txt</td>\n",
       "      <td>Fast and accurate sentiment classification usi...</td>\n",
       "      <td>Abstract. We have explored different methods o...</td>\n",
       "      <td>['We used a publicly available dataset of movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:/Users/sojood/Desktop/papers-text/Text Files/</td>\n",
       "      <td>1306.6802v2.txt</td>\n",
       "      <td>Evaluation Measures for Hierarchical Classiﬁca...</td>\n",
       "      <td>Hierarchical classiﬁcation addresses the probl...</td>\n",
       "      <td>['1. It groups existing HC evaluation measures...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:/Users/sojood/Desktop/papers-text/Text Files/</td>\n",
       "      <td>1308.0850v5.txt</td>\n",
       "      <td>Generating Sequences With Recurrent Neural Net...</td>\n",
       "      <td>This paper shows how Long Short-term Memory re...</td>\n",
       "      <td>['Long Short-term Memory (LSTM) [16] is an RNN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Directory  \\\n",
       "0  C:/Users/sojood/Desktop/papers-text/Text Files/   \n",
       "1  C:/Users/sojood/Desktop/papers-text/Text Files/   \n",
       "2  C:/Users/sojood/Desktop/papers-text/Text Files/   \n",
       "3  C:/Users/sojood/Desktop/papers-text/Text Files/   \n",
       "4  C:/Users/sojood/Desktop/papers-text/Text Files/   \n",
       "5  C:/Users/sojood/Desktop/papers-text/Text Files/   \n",
       "6  C:/Users/sojood/Desktop/papers-text/Text Files/   \n",
       "7  C:/Users/sojood/Desktop/papers-text/Text Files/   \n",
       "\n",
       "                            FileName  \\\n",
       "0  1-s2.0-S2211381912001087-main.txt   \n",
       "1                      1012.2609.txt   \n",
       "2                    1207.1847v1.txt   \n",
       "3                    1209.3126v1.txt   \n",
       "4                      1210.0852.txt   \n",
       "5                      1305.6143.txt   \n",
       "6                    1306.6802v2.txt   \n",
       "7                    1308.0850v5.txt   \n",
       "\n",
       "                                               Title  \\\n",
       "0          Available online at www.sciencedirect.com   \n",
       "1  J OURNAL OF I NFORMATION S CIENCE AND E NGINEE...   \n",
       "2                          The University of Sheﬃeld   \n",
       "3                 Beyond Stemming and Lemmatization:   \n",
       "4  Detecting multiword phrases in mathematical te...   \n",
       "5  Fast and accurate sentiment classification usi...   \n",
       "6  Evaluation Measures for Hierarchical Classiﬁca...   \n",
       "7  Generating Sequences With Recurrent Neural Net...   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  Many modern service systems rely on a network ...   \n",
       "1  Term weighting schemes often dominate the perf...   \n",
       "2  The statistical methods derived and described ...   \n",
       "3  In Automatic Text Summarization, preprocessing...   \n",
       "4  We present an approach for detecting multiword...   \n",
       "5  Abstract. We have explored different methods o...   \n",
       "6  Hierarchical classiﬁcation addresses the probl...   \n",
       "7  This paper shows how Long Short-term Memory re...   \n",
       "\n",
       "                                                Text  \n",
       "0  ['While the ROASWSN design decision is to sele...  \n",
       "1  ['*   This work was supported supported by the...  \n",
       "2  ['Part 3.    Applications                     ...  \n",
       "3  ['\\ufeff\\x0c', 'a heterogeneous set of documen...  \n",
       "4  ['•   locally symmetrical Finsler manifold(s) ...  \n",
       "5  ['We used a publicly available dataset of movi...  \n",
       "6  ['1. It groups existing HC evaluation measures...  \n",
       "7  ['Long Short-term Memory (LSTM) [16] is an RNN...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=read_papers('C:/Users/sojood/Desktop/papers-text/Text Files/')\n",
    "\n",
    "data.head(n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map the contracted words with their intended meanings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What are contractions?\n",
    "\n",
    "Contractions are words or combinations of words that are shortened by dropping letters and replacing them by an apostrophe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_map = {\n",
    "                   \"ain't\": \"is not\", \n",
    "                   \"aren't\": \"are not\",\n",
    "                   \"can't\": \"cannot\", \n",
    "                   \"'cause\": \"because\",\n",
    "                   \"could've\": \"could have\",\n",
    "                   \"couldn't\": \"could not\",\n",
    "                   \"didn't\": \"did not\", \n",
    "                   \"doesn't\": \"does not\", \n",
    "                   \"don't\": \"do not\", \n",
    "                   \"hadn't\": \"had not\",\n",
    "                   \"hasn't\": \"has not\", \n",
    "                   \"haven't\": \"have not\",\n",
    "                   \"he'd\": \"he would\",\n",
    "                   \"he'll\": \"he will\",\n",
    "                   \"he's\": \"he is\", \n",
    "                   \"how'd\": \"how did\", \n",
    "                   \"how'd'y\": \"how do you\", \n",
    "                   \"how'll\": \"how will\", \n",
    "                   \"how's\": \"how is\",\n",
    "                   \"I'd\": \"I would\", \n",
    "                   \"I'd've\": \"I would have\",\n",
    "                   \"I'll\": \"I will\",\n",
    "                   \"I'll've\": \"I will have\",\n",
    "                   \"I'm\": \"I am\",\n",
    "                   \"I've\": \"I have\", \n",
    "                   \"i'd\": \"i would\",\n",
    "                   \"i'd've\": \"i would have\",\n",
    "                   \"i'll\": \"i will\", \n",
    "                   \"i'll've\": \"i will have\",\n",
    "                   \"i'm\": \"i am\", \n",
    "                   \"i've\": \"i have\",\n",
    "                   \"isn't\": \"is not\", \n",
    "                   \"it'd\": \"it would\",\n",
    "                   \"it'd've\": \"it would have\",\n",
    "                   \"it'll\": \"it will\",\n",
    "                   \"it'll've\": \"it will have\",\n",
    "                   \"it's\": \"it is\",\n",
    "                   \"let's\": \"let us\",\n",
    "                   \"ma'am\": \"madam\",\n",
    "                   \"mayn't\": \"may not\",\n",
    "                   \"might've\": \"might have\",\n",
    "                   \"mightn't\": \"might not\",\n",
    "                   \"mightn't've\": \"might not have\",\n",
    "                   \"must've\": \"must have\",\n",
    "                   \"mustn't\": \"must not\", \n",
    "                   \"mustn't've\": \"must not have\",\n",
    "                   \"needn't\": \"need not\", \n",
    "                   \"needn't've\": \"need not have\",\n",
    "                   \"o'clock\": \"of the clock\",\n",
    "                   \"oughtn't\": \"ought not\", \n",
    "                   \"oughtn't've\": \"ought not have\",\n",
    "                   \"shan't\": \"shall not\", \n",
    "                   \"sha'n't\": \"shall not\", \n",
    "                   \"shan't've\": \"shall not have\",\n",
    "                   \"she'd\": \"she would\", \n",
    "                   \"she'd've\": \"she would have\",\n",
    "                   \"she'll\": \"she will\",\n",
    "                   \"she'll've\": \"she will have\",\n",
    "                   \"she's\": \"she is\",\n",
    "                   \"should've\": \"should have\",\n",
    "                   \"shouldn't\": \"should not\",\n",
    "                   \"shouldn't've\": \"should not have\",\n",
    "                   \"so've\": \"so have\",\n",
    "                   \"so's\": \"so as\",\n",
    "                   \"this's\": \"this is\",\n",
    "                   \"that'd\": \"that would\", \n",
    "                   \"that'd've\": \"that would have\", \n",
    "                   \"that's\": \"that is\", \n",
    "                   \"there'd\": \"there would\",\n",
    "                   \"there'd've\": \"there would have\", \n",
    "                   \"there's\": \"there is\", \n",
    "                   \"here's\": \"here is\",\n",
    "                   \"they'd\": \"they would\",\n",
    "                   \"they'd've\": \"they would have\",\n",
    "                   \"they'll\": \"they will\", \n",
    "                   \"they'll've\": \"they will have\",\n",
    "                   \"they're\": \"they are\",\n",
    "                   \"they've\": \"they have\", \n",
    "                   \"to've\": \"to have\",\n",
    "                   \"wasn't\": \"was not\",\n",
    "                   \"we'd\": \"we would\", \n",
    "                   \"we'd've\": \"we would have\",\n",
    "                   \"we'll\": \"we will\",\n",
    "                   \"we'll've\": \"we will have\",\n",
    "                   \"we're\": \"we are\",\n",
    "                   \"we've\": \"we have\", \n",
    "                   \"weren't\": \"were not\", \n",
    "                   \"what'll\": \"what will\", \n",
    "                   \"what'll've\": \"what will have\", \n",
    "                   \"what're\": \"what are\",\n",
    "                   \"what's\": \"what is\",\n",
    "                   \"what've\": \"what have\",\n",
    "                   \"when's\": \"when is\", \n",
    "                   \"when've\": \"when have\", \n",
    "                   \"where'd\": \"where did\", \n",
    "                   \"where's\": \"where is\",\n",
    "                   \"where've\": \"where have\", \n",
    "                   \"who'll\": \"who will\", \n",
    "                   \"who'll've\": \"who will have\",\n",
    "                   \"who's\": \"who is\", \n",
    "                   \"who've\": \"who have\",\n",
    "                   \"why's\": \"why is\",\n",
    "                   \"why've\": \"why have\", \n",
    "                   \"will've\": \"will have\", \n",
    "                   \"won't\": \"will not\",\n",
    "                   \"won't've\": \"will not have\",\n",
    "                   \"would've\": \"would have\",\n",
    "                   \"wouldn't\": \"would not\",\n",
    "                   \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                   \"y'all'd\": \"you all would\",\n",
    "                   \"y'all'd've\": \"you all would have\",\n",
    "                   \"y'all're\": \"you all are\",\n",
    "                   \"y'all've\": \"you all have\",\n",
    "                   \"you'd\": \"you would\", \n",
    "                   \"you'd've\": \"you would have\",\n",
    "                   \"you'll\": \"you will\", \n",
    "                   \"you'll've\": \"you will have\",\n",
    "                   \"you're\": \"you are\",\n",
    "                   \"you've\": \"you have\"\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clean the text and abstract using the contrcation_mapping and removing irrelevant letters and words. Finally,tokenize the sentences for further processing.\n",
    "1-Remove stop words\n",
    "2-Convert to lower case\n",
    "3-Replace digit number with space\n",
    "4-remove short words\n",
    "\n",
    "Apply preproessing function on paper text and abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re        \n",
    "import numpy as np  \n",
    "from bs4 import BeautifulSoup \n",
    "from nltk.corpus import stopwords   \n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "\n",
    "def summary_cleaner(text):\n",
    "    newString = text.lower()\n",
    "    newString = re.sub('\"','', str(text))\n",
    "    newString = ' '.join([contraction_map[t] if t in contraction_map else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
    "    newString = newString.lower()\n",
    "    tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>=3:                  #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()\n",
    "\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(summary_cleaner(t))\n",
    "    \n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(summary_cleaner(t))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Drop nan value (nul value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cleaned_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roaswsn design decision select hub arcs flow c...</td>\n",
       "      <td>many modern service systems rely network hub f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>work supported supported high tech program gra...</td>\n",
       "      <td>term weighting schemes often dominate performa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>part applications chapter collocation coocurre...</td>\n",
       "      <td>statistical methods derived described thesis p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ufeff heterogeneous set documents focused topi...</td>\n",
       "      <td>automatic text summarization preprocessing imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>locally symmetrical finsler manifold local equ...</td>\n",
       "      <td>present approach detecting multiword phrases m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>used publicly available dataset movie reviews ...</td>\n",
       "      <td>abstract explored different methods improving ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>groups existing evaluation measures two main t...</td>\n",
       "      <td>hierarchical classi cation addresses problem c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>long short term memory lstm rnn architecture d...</td>\n",
       "      <td>paper shows long short term memory recurrent n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text  \\\n",
       "0  roaswsn design decision select hub arcs flow c...   \n",
       "1  work supported supported high tech program gra...   \n",
       "2  part applications chapter collocation coocurre...   \n",
       "3  ufeff heterogeneous set documents focused topi...   \n",
       "4  locally symmetrical finsler manifold local equ...   \n",
       "5  used publicly available dataset movie reviews ...   \n",
       "6  groups existing evaluation measures two main t...   \n",
       "7  long short term memory lstm rnn architecture d...   \n",
       "\n",
       "                                     cleaned_summary  \n",
       "0  many modern service systems rely network hub f...  \n",
       "1  term weighting schemes often dominate performa...  \n",
       "2  statistical methods derived described thesis p...  \n",
       "3  automatic text summarization preprocessing imp...  \n",
       "4  present approach detecting multiword phrases m...  \n",
       "5  abstract explored different methods improving ...  \n",
       "6  hierarchical classi cation addresses problem c...  \n",
       "7  paper shows long short term memory recurrent n...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary\n",
    "data['cleaned_summary'].replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)\n",
    "dataa = data.filter(['cleaned_text','cleaned_summary'], axis=1)\n",
    "dataa.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Into Train/Test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test size = 20%\n",
    "X= cleaned text(paper text after clean)\n",
    "y=cleaned summary (original abstract after clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(dataa['cleaned_text'],dataa['cleaned_summary'],test_size=0.2,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of the sequences"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Distribution of the sequence of summary word count and cleaned text word count , also use this distribution \n",
    "to define maximum length text and maxiumam sumarry length text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeWElEQVR4nO3de5SdVZnn8e9PLoEG2oBgGUPshCbiAqIBMogDbae5hugYnIV0shhIgBmkB9bAmmolQUe0kRnsMdAyOtw6NIFGElpAMoItEaiFWdOABEIIhDQFhiFZIZE7icKywjN/vLvgrZNTdS51bvXW77PWWee8+72c55x6z1P77LPfvRURmJlZsXyo3QGYmVnjObmbmRWQk7uZWQE5uZuZFZCTu5lZATm5m5kVkJO7mVkBObm3kaT1ko7vlOOYWXE4uZvZqCBp53bH0EpO7m0i6RbgE8D/kbRV0tclHSXp/0p6Q9KTkqanbf+tpFckTUjLn5H0uqRPlTtOu16TFZ+kiyVtlPS2pHWSjpN0k6Tv5raZLmlDbnm9pK9JWi1pm6RFkrok/Twd55eS9k7bTpQUks6S9FI6z8+T9G/S/m9I+mHu2H8q6QFJr6bPyK2SxpY898WSVgPbUhx3lLymqyX9oJnvW1tEhG9tugHrgePT4/HAq8BMsn+6J6Tl/dL6y4EHgN2Bp4ALyh3HN9+adQMOAl4CPp6WJwJ/CtwEfDe33XRgQ255PfAw0JXO8y3A48BhwG7pvL40d8wArk3rTgTeAX4KfDS3/5+n7Q9Mn5UxwH7AQ8DflTz3KmBC+uyMA7YBY9P6ndPxjmj3+9vom2vuneM/APdGxL0R8V5ELAceI0v2AN8GPgw8CmwEftSWKG00206WRA+WtEtErI+I56vc939FxOaI2Aj8CngkIp6IiHeAu8gSfd5lEfFORNxHloxvi4gtuf0PA4iI3ohYHhHvRsRvgSuBPy851tUR8VJE/D4iNpH9A/hKWjcDeCUiVtb0TowATu6d40+Ar6SvnW9IegM4hqymQUT8gayGdCiwMFK1w6xVIqIXuIisorFF0hJJH69y9825x78vs7xnPdun5p0lqanoLeAfgX1LjvVSyfJissoU6f6WKl/DiOLk3l75BP0ScEtEjM3d9oiIKwAkjQcuBf4BWChpzCDHMWuaiPhxRBxDVhkJ4HtkNes/ym32sRaG9N9THFMi4o/JkrVKtin9fPwU+LSkQ4EvArc2O8h2cHJvr83AAenxPwL/TtJJknaStFv6YWp/SSKrtS8CzgE2AZcNchyzppB0kKRjU8XiHbIa9HtkbdozJe0j6WNktftW2QvYCryZKkBfq7RDagr6CfBj4NGI+H/NDbE9nNzb638A30xNMH8JzAIuAX5LVpP/Gtnf6L+Q/Zj031JzzFnAWZL+rPQ4kv66tS/BRpExwBXAK8DLZOfkArJmjSfJfry8D1jawpi+AxwOvAncA9xZ5X6LgSkUtEkGQG66NbPRRtIngGeBj0XEW+2OpxlcczezUUXSh4D/CiwpamKHrI+nmdmoIGkPst+oXiTrBllYbpYxMysgN8uYmRVQRzTL7LvvvjFx4sQBZdu2bWOPPfZoT0BDcFy1aWVcK1eufCUi9mvJkw1TuXMeOvfv2Ex+zfUb8pxv9/gHEcERRxwRpR588MEdyjqB46pNK+MCHosOOJ+ruZU75yM69+/YTH7N9RvqnHezjJlZATm5m5kVkJO7mVkBObmbmRWQk7uZWQE5uZuZFZCTu5lZATm5m5kVUNXJPU0g8YSkn6XlSZIekdQraamkXVP5mLTcm9ZPbFLsZmY2iFqGH7gQWAv8cVr+HnBVRCyRdC3ZDEHXpPvXI+JASbPTdn/ZwJh3MHH+PQOW11/xhWY+nVlT+Xy2Rqiq5i5pf+ALwN+nZQHHkk1VBdmsJqekx7PSMmn9cWl7MzNrkWpr7n8HfJ1svkKAjwBvRERfWt4AjE+Px5NmG4+IPklvpu1fyR9Q0rnAuQBdXV309PQMeMKtW7fuUDaY7il9A5ar3a8etcTVSo6rcSTdSDZx8paIODSVLQUOSpuMJTv/p6Zmx7XAurTu4Yg4r7URm+2oYnKX1H+Sr5Q0vVFPHBHXA9cDTJs2LaZPH3jonp4eSssGM6/0a+zp1e1Xj1riaiXH1VA3AT8Ebu4viIj3mxYlLSSbs7Pf8xExtVXBmVWjmpr70cCXJM0EdiNrc/8BMFbSzqn2vj+wMW2/EZgAbJC0M/Bh4NWGR27WJBHx0GAdAVIT42lkzZJmHatico+IBWQznJNq7n8dEadL+ifgVGAJMBe4O+2yLC3/S1r/QBqa0qwI/gzYHBHP5comSXoCeAv4ZkT8qtyOlZoiIWvG6p6yfUDZSGvWqtVIbLobrla85uFM1nExsETSd4EngEWpfBFwi6Re4DVg9vBCNOsoc4DbcsubgE9ExKuSjgB+KumQKDPxcqWmSMgS+cIV2waUNbOZsROM0Ka7YWnFa64puUdED9CTHr8AHFlmm3eArzQgNrOOkpoZ/z1wRH9ZRLwLvJser5T0PPBJ4LG2BGmW+ApVs+odDzwbERv6CyTtJ2mn9PgAYDLwQpviM3ufk7tZCUm3kf1mdJCkDZLOSatmM7BJBuDzwGpJq8iu6zgvIl5rWbBmg+iICbLNOklEzBmkfF6ZsjuAO5odk1mtXHM3MysgJ3czswJycjczKyAndzOzAnJyNzMrICd3M7MCcnI3MysgJ3czswJycjczKyAndzOzAnJyNzMrICd3M7MCcnI3MysgJ3czswKqmNwl7SbpUUlPSnpa0ndS+U2SfiNpVbpNTeWSdLWkXkmrJR3e5NdgZmYlqhnP/V3g2IjYKmkXYIWkn6d1X4uIn5RsfzLZbDSTgc8C16R7MzNrkYo198hsTYu7pFsMscss4Oa038PAWEnjhh+qmZlVq6qZmNIckSuBA4EfRcQjkv4KuFzSt4D7gflpsuDxwEu53Teksk0lxzwXOBegq6uLnp6eAc+5devWHcoG0z2lb8BytfvVo5a4WslxmVleVck9IrYDUyWNBe6SdCiwAHgZ2BW4HrgY+Jtqnzgirk/7MW3atJg+ffqA9T09PZSWDWbe/HsGLK8/vbr96lFLXK3kuMwsr6beMhHxBvAgMCMiNqWml3eBfwCOTJttBCbkdts/lZmZWYtU01tmv1RjR9LuwAnAs/3t6JIEnAKsSbssA85MvWaOAt6MiE07HNisg0m6UdIWSWtyZd+WtDHXQ2xmbt2C1ENsnaST2hO12QeqaZYZByxO7e4fAm6PiJ9JekDSfoCAVcB5aft7gZlAL/A74KyGR23WfDcBPwRuLim/KiK+ny+QdDAwGzgE+DjwS0mfTM2ZZm1RMblHxGrgsDLlxw6yfQDnDz80s/aJiIckTaxy81nAktRE+RtJvWTNlP/SrPjMKqnqB1Uze98Fks4EHgO6I+J1st5gD+e26e8hNkClHmKQ9S7qnjKwwl/03kajsUdVK16zk7tZ9a4BLiO7zuMyYCFwdrU7V+ohBlkiX7hi24CyZvb+6gSjsUdVK16zx5Yxq1JEbI6I7RHxHnAD7iFmHczJ3axKJVdaf5mBPcRmSxojaRLZ0BuPtjo+szw3y5iVIek2YDqwr6QNwKXA9DRAXgDrga8CRMTTkm4HngH6gPPdU8bazcndrIyImFOmeNEQ218OXN68iMxq42YZM7MCcnI3MysgJ3czswJycjczKyAndzOzAnJyNzMrICd3M7MCcnI3MysgJ3czswJycjczK6BqptnbTdKjkp6U9LSk76TySZIeSVOLLZW0ayofk5Z70/qJTX4NZmZWopqa+7vAsRHxGWAqMCPNjfo9sinHDgReB85J258DvJ7Kr0rbmZlZC1VM7pHZmhZ3SbcAjgV+ksoXk02SDdmUY4vT458Ax6VJtM3MrEWqGhUyTY69EjgQ+BHwPPBGRPSlTfLTio0HXgKIiD5JbwIfAV4pOeaQU47VMg1V95S+AcvNnL6qU6cEc1xmlldVck9jU0+VNBa4C/jUcJ+40pRjtUxDNW/+PQOWmzktWadOCea4zCyvpt4yEfEG8CDwOWCspP5/Dvlpxd6fciyt/zDwaiOCNTOz6lTTW2a/VGNH0u7ACcBasiR/atpsLnB3erwsLZPWPxAR0cCYzcysgmqaZcYBi1O7+4eA2yPiZ5KeAZZI+i7wBB/MUrMIuEVSL/AaMLsJcZuZ2RAqJveIWA0cVqb8BT6Y/T1f/g7wlYZEZ2ZmdfEVqmZmBeTkblZC0o2Stkhakyv7n5KelbRa0l2536EmSvq9pFXpdm3bAjfLcXI329FNwIySsuXAoRHxaeBfgQW5dc9HxNR0O69FMZoNycndrEREPETWGSBfdl/uor2Hybr/mnWsqi5iMrMBzgaW5pYnSXoCeAv4ZkT8qtxOla7KhuyK3u4p2weUFf0K39F4FXMrXrOTu1kNJH0D6ANuTUWbgE9ExKuSjgB+KumQiHirdN9KV2VDlsgXrtg2oKyZV1x3gtF4FXMrXrObZcyqJGke8EXg9P4L8yLi3Yh4NT1eSTbu0ifbFqRZ4uRuVgVJM4CvA1+KiN/lyvdLF/gh6QBgMvBCe6I0+4CbZcxKSLoNmA7sK2kDcClZ75gxwPI0gvXDqWfM54G/kfQH4D3gvIh4reyBzVrIyd2sRETMKVO8qEwZEXEHcEdzIzKrnZtlzMwKyMndzKyAnNzNzArIyd3MrICc3M3MCsjJ3cysgJzczcwKqJo5VCdIelDSM5KelnRhKv+2pI25caxn5vZZIKlX0jpJJzXzBZiZ2Y6quYipD+iOiMcl7QWslLQ8rbsqIr6f31jSwWTzph4CfBz4paRPRsTAoe7qNHH+PY04jJlZoVWsuUfEpoh4PD1+G1gLjB9il1nAkjSg0m+AXsrMtWpmZs1T0/ADkiaSTZb9CHA0cIGkM4HHyGr3r5Ml/odzu22gzD+DSmNbDzbecfeUvh3KSjVznOROHXvacZlZXtXJXdKeZGNoXBQRb0m6BrgMiHS/kGwSg6pUGtt6sPGO51XRLNPM8a87dexpx2VmeVX1lpG0C1livzUi7gSIiM0RsT0i3gNu4IOml43AhNzu+6cyMzNrkWp6y4hsRLy1EXFlrnxcbrMvA/0zxS8DZksaI2kS2fjWjzYuZDMzq6SaZpmjgTOApyStSmWXAHMkTSVrllkPfBUgIp6WdDvwDFlPm/Mb1VPGzMyqUzG5R8QKQGVW3TvEPpcDlw8jLjMzGwZfoWpmVkBO7mZmBeTkbmZWQE7uZmYFVMgJskvHn1l/xRfaFImNVJJuBL4IbImIQ1PZPsBSYCJZD7HTIuL11F34B8BM4HfAvP4hO8zaxTV3s/JuAmaUlM0H7o+IycD9aRngZLLrOSaTDalxTYtiNBuUk7tZGRHxEPBaSfEsYHF6vBg4JVd+c2QeBsaWXORn1nKFbJYxa5KuiNiUHr8MdKXH44GXctv1D5a3KVdWcbA8yAZa654y8Jq/og+8NhoHl2vFa3ZyN6tDRISkqHGfIQfLgyyRL1yxbUBZMwfC6wSjcXC5VrxmN8uYVW9zf3NLut+Syj1YnnUcJ3ez6i0D5qbHc4G7c+VnKnMU8Gau+casLdwsY1aGpNuA6cC+kjYAlwJXALdLOgd4ETgtbX4vWTfIXrKukGe1PGCzEk7uZmVExJxBVh1XZtsAzm9uRGa1cbOMmVkBObmbmRWQk7uZWQFVM83eBEkPSnpG0tOSLkzl+0haLum5dL93KpekqyX1Slot6fBmvwgzMxuompp7H9AdEQcDRwHnSzoYj7NhZtaxKib3iNjUP8JdRLwNrCW7tNrjbJiZdaia2twlTQQOAx6h9nE2zMysRaru5y5pT+AO4KKIeCsbwjpTzzgblQZRGmxgne4pfbU8DdDYgZc6dZAjx2VmeVUld0m7kCX2WyPizlS8WdK4iNhUzzgblQZRGmxgnXklE3FUo5EDL3XqIEeOy8zyquktI2ARsDYirsyt8jgbZmYdqpqa+9HAGcBTklalskvwOBtmNghPddl+FZN7RKwANMhqj7NhZtaBfIWqmVkBObmbmRWQk7uZWQE5uZuZFZAn6zCzpnPvmdZzzd3MrICc3M3MCsjNMmZVknQQsDRXdADwLWAs8J+A36bySyLi3tZGZzaQk7tZlSJiHTAVQNJOZGMm3UV2FfZVEfH99kVnNpCbZczqcxzwfES82O5AzMpxcjerz2zgttzyBWlayRv7p5w0ayc3y5jVSNKuwJeABanoGuAyINL9QuDsMvsNOYcBZOPfd0/ZPqBsJI6HX2nehfxrGo1j/rfiNTu5m9XuZODxiNgM0H8PIOkG4Gfldqo0hwFkSW/him0Dyho5H0GrVJp3If+aRuOY/614zW6WMavdHHJNMiVzBH8ZWNPyiMxKuOZuVgNJewAnAF/NFf+tpKlkzTLrS9YVXunVp9YZnNzNahAR24CPlJSd0aZwzAblZhkzswKqZg7VGyVtkbQmV/ZtSRslrUq3mbl1CyT1Slon6aRmBW5mZoOrpuZ+EzCjTPlVETE13e4FkHQwWf/fQ9I+/ztdyWdmZi1UMblHxEPAa1UebxawJCLejYjfkE2SfeQw4jMzszoM5wfVCySdCTwGdEfE68B44OHcNhtS2Q4qXdAxWCf/ShdHlNPIiwU69YILx2VmefUm96quyBtKpQs6BuvkX+niiHIaeRFIp15w4bjMLK+u3jIRsTkitkfEe8ANfND0shGYkNt0/1RmZmYtVFdyH+KKvGXAbEljJE0CJgOPDi9EMzOrVcVmGUm3AdOBfSVtAC4Fppe7Ii8inpZ0O/AM0AecHxHbyxzWzMyaqGJyj4g5ZYoXDbH95cDlwwnKzMyGx1eompkVkMeWMbOWyw821j2lj3nz72H9FV9oY0TF45q7mVkBObmbmRWQk7uZWQE5uZuZFZB/UDWzjlA6o5N/YB0e19zNzArINXczq0mr5kwt9zyuzVfPNXczswJyzd2sRpLWA28D24G+iJgmaR9gKTCRbLyl09IcB2Zt4Zq7WX3+Ik0xOS0tzwfuj4jJwP1p2axtnNzNGmMWsDg9Xgyc0r5QzNwsY1aPAO6TFMB1aVaxrojYlNa/DHSV7lRpaknIpiXsnjJwlOxOm6awnqkuh9K1e/XH7LT3ol6tmH7Syd2sdsdExEZJHwWWS3o2vzIiIiV+SsqHnFoSsuS1cMW2AWWNnCayEeqZ6nIo3VP6WPhUdamo096LerVi+kk3y5jVKCI2pvstwF1k00xu7p+hLN1vaV+EZk7uZjWRtIekvfofAyeSTTO5DJibNpsL3N2eCM0yFZO7pBslbZG0Jle2j6Tlkp5L93unckm6WlKvpNWSDm9m8GZt0AWskPQk2fzA90TEPwNXACdIeg44Pi2btU01NfebgBklZYN1+zqZbFLsyWQ/HF3TmDDNOkNEvBARn0m3Q9K0kkTEqxFxXERMjojjI+K1dsdqo1vF5B4RDwGlJ+pg3b5mATdH5mFgbH87pJmZtU69vWUG6/Y1Hngpt92GVLaJEpW6hQ3WVaiebliN7HLUii5M9XBcNhp45MjqDbsr5GDdvqrYb8huYYN1FaqnG1Yju0+1ogtTPRyXNUOrBgmzxqu3t8xg3b42AhNy2+2fyszMrIXqTe6DdftaBpyZes0cBbyZa74xM7MWqdgsI+k2YDqwr6QNwKVk3bxul3QO8CJwWtr8XmAm0Av8DjirCTGbmVkFFZN7RMwZZNVxZbYN4PzhBmVmH/CkFVYPX6FqZlZATu5mZgXkUSHNbMRyv/fBObmbjWJOjsXlZhkzswJycjczKyAndzOzAnJyNzMrICd3M7MCcm8ZM3vfSB8F0lfzfsA1dzOzAnLN3ayg3Id9dHPN3cysgJzczaokaYKkByU9I+lpSRem8m9L2ihpVbrNbHesZm6WMateH9AdEY9L2gtYKWl5WndVRHy/jbGZDeDkblalNKvYpvT4bUlrySaAN+s4w0ruktYDbwPbgb6ImCZpH2ApMBFYD5wWEa/X+xyN6Jrl7lHWaJImAocBjwBHAxdIOhN4jKx2v8M5L+lc4FyArq4uenp6djju1q1b6Z6yveLzl9u3VPeUvor7lG7TDl27NzeOat6rVtu6dWvT42pEzf0vIuKV3PJ84P6IuELS/LR8cQOex6wjSNoTuAO4KCLeknQNcBkQ6X4hcHbpfhFxPXA9wLRp02L69Ok7HLunp4eFK7ZVjGH96TvuW2peaW+ZMvuUbtMO3VP6WPhU8xoRqnmvWq2np4dyf/9GasYPqrOAxenxYuCUJjyHWVtI2oUssd8aEXcCRMTmiNgeEe8BNwBHtjNGMxh+zT2A+yQFcF2qmXSltkmAl4GucjtW+ora/7WlWV/X6v1K1IqvU/VwXM0nScAiYG1EXJkrH5c7578MrGlHfGZ5w03ux0TERkkfBZZLeja/MiIiJf4dVPqK2v+1pVlfG+v9qtaKr1P1cFwtcTRwBvCUpFWp7BJgjqSpZJWd9cBX2xGcWd6wkntEbEz3WyTdRfZ1dHN/TUbSOGBLA+I0a7uIWAGozKp7Wx1LqWo6Hoz0cWOsNnW3uUvaI/X1RdIewIlkX0eXAXPTZnOBu4cbpJmZ1WY4Nfcu4K6sGZKdgR9HxD9L+jVwu6RzgBeB04YfppmZ1aLu5B4RLwCfKVP+KnDccIIyM7Ph8RWqZlZoo3V0TA8cZmZWQE7uZmYF5ORuZlZATu5mZgXk5G5mVkDuLWM2Avlq0/qNliHAndzNzEoU4R+Am2XMzApo1NbcR+uFDWa2o3oGXuv0nOGau5lZATm5m5kVkJO7mVkBjdo291JF+HXczKyfa+5mZgXk5G5mVkBuljEzq0Ond41sWnKXNAP4AbAT8PcRcUWznsusE/icH9067Xe7piR3STsBPwJOADYAv5a0LCKeacbztcrE+ffQPaWPebk/Yqf9t7b2KOo5byNXs2ruRwK9aZ5VJC0BZgEj6kSv56q1Rqnnn0Y1sZQet574y8XWrK+onf7VN6cQ57w1Vj3nb6POeUVEXTsOeVDpVGBGRPzHtHwG8NmIuCC3zbnAuWnxIGBdyWH2BV5peHDD57hq08q4/iQi9mvRcw3QoHMeOvfv2Ex+zfUb9Jxv2w+qEXE9cP1g6yU9FhHTWhhSVRxXbTo1rnaodM7D6Hy//Jqbo1ldITcCE3LL+6cys6LyOW8dpVnJ/dfAZEmTJO0KzAaWNem5zDqBz3nrKE1plomIPkkXAL8g6xZ2Y0Q8XeNhhvz62kaOqzadGldDNeich1HyfpXwa26CpvygamZm7eXhB8zMCsjJ3cysgDoyuUuaIWmdpF5J85tw/BslbZG0Jle2j6Tlkp5L93unckm6OsWyWtLhuX3mpu2fkzQ3V36EpKfSPldLUpVxTZD0oKRnJD0t6cJOiE3SbpIelfRkius7qXySpEfSsZamHxKRNCYt96b1E3PHWpDK10k6KVfe1L/5SFDU96BRn7eRopGf42GJiI66kf0Y9TxwALAr8CRwcIOf4/PA4cCaXNnfAvPT4/nA99LjmcDPAQFHAY+k8n2AF9L93unx3mndo2lbpX1PrjKuccDh6fFewL8CB7c7trTtnunxLsAj6Ri3A7NT+bXAX6XH/xm4Nj2eDSxNjw9Of88xwKT0d96pFX/zTr8V+T1oxOdtJN0a9TkedhztfiPKvDGfA36RW14ALGjC80wsOdnWAeNyf5x16fF1wJzS7YA5wHW58utS2Tjg2Vz5gO1qjPFusrFKOiY24I+Ax4HPkl1ht3Pp342sx8jn0uOd03Yq/Vv2b9eqv3kn34r+Hgz389bu+If52uv6HA/3eTuxWWY88FJueUMqa7auiNiUHr8MdFWIZ6jyDWXKa5KaMg4jqyW3PTZJO0laBWwBlpPVMt+IiL4yx3r/+dP6N4GP1BHvaDLa3oNaz+kRaZif42HpxOTedpH9+2xbH1FJewJ3ABdFxFv5de2KLSK2R8RUsisvjwQ+1eoYrJja/XlrlnZ/jjsxubfrMu7NksYBpPstFeIZqnz/MuVVkbQL2Qlxa0Tc2UmxAUTEG8CDZM0IYyX1XwiXP9b7z5/Wfxh4tY54R5PR9h7Uek6PKA36HA9LJyb3dl3GvQzo71Uyl6ydrL/8zPSL9lHAm+mr1S+AEyXtnX71PpGszXQT8Jako1JPlDNzxxpS2n4RsDYiruyU2CTtJ2lserw7WfvhWrIkf+ogcfXHeyrwQKqpLANmp940k4DJZD/w+tL90fce1HpOjxgN/BwPT7t/bBjkB4iZZL8wPw98ownHvw3YBPyBrH3rHLI24fuB54BfAvukbUU2CcPzwFPAtNxxzgZ60+2sXPk0YE3a54ekK4GriOsYsq9qq4FV6Taz3bEBnwaeSHGtAb6Vyg8gS869wD8BY1L5bmm5N60/IHesb6TnXkeup06z/+Yj4VbU96BRn7eRcmvk53g4Nw8/YGZWQJ3YLGNmZsPk5G5mVkBO7mZmBeTkbmZWQE7uZmYF5ORuZlZATu5mZgX0/wHcGstTkJ89QAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in dataa['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in dataa['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the lengths for summary and text.\n",
    "max_len_text=500\n",
    "max_len_summary=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Text Tokenizer & Summary Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for text on training data\n",
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr,  maxlen=max_len_text, padding='post') \n",
    "x_val   =   pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
    "\n",
    "x_voc_size   =  len(x_tokenizer.word_index) +1\n",
    "\n",
    "\n",
    "#preparing a tokenizer for summary on training data \n",
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert summary sequences into integer sequences\n",
    "y_tr    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
    "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
    "\n",
    "y_voc_size  =   len(y_tokenizer.word_index) +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Build the model. Key components of the model are as follows:\n",
    "\n",
    "1- Encoder- Encoder_inputs is used in order to encode the words into numeric data for processing by LSTM layers.\n",
    "2-LSTM Layers- We use 3 LSTM layers in order to process the data effectively. You can also experiment by adding or removing the layers in order to find more better accuracies. return_sequences in LSTM layer is set true until we want to add more layers consecutively.\n",
    "3-Decoder- Decoder again converts the numeric data into the understandable word formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import backend as K \n",
    "K.clear_session()\n",
    "#\"latent_dim\" is the number of nodes used as input of the generator\n",
    "latent_dim = 500 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attension layer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Adding the Attention layer: Attention layer is used to selectively choose the relevant information while discarding the non-useful information by cognitively mapping the generated sentences with the inputs of encoder layer.\n",
    "Dense Layer: It mathematically represents the matrix vector multiplication in neurons and is used to change the dimensions of the vectors for processing between various layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
    "            if verbose:\n",
    "                print('wa.s>',W_a_dot_s.shape)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>',U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        def create_inital_state(inputs, hidden_size):\n",
    "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
    "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
    "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
    "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
    "            return fake_state\n",
    "\n",
    "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
    "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        return fake_state_c, fake_state_e\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # Encoder \n",
    "    encoder_inputs = Input(shape=(max_len_text,)) \n",
    "    enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
    "    #Preparing LSTM layer 1 \n",
    "    encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "    encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "    #Preparing LSTM layer 2\n",
    "    encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "    encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "    #Preparing LSTM layer 3\n",
    "    encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "    encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
    "    # Decoder layer \n",
    "    decoder_inputs = Input(shape=(None,)) \n",
    "    dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
    "    dec_emb = dec_emb_layer(decoder_inputs) \n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "    decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "    #Attention Layer\n",
    "    attn_layer = AttentionLayer(name='attention_layer') \n",
    "    attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "    #Adding the dense layer\n",
    "    decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
    "    decoder_outputs = decoder_dense(decoder_outputs) \n",
    "    # Prepare the model\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "    # Compiling the RNN model\n",
    "    #Compilation\n",
    "    #Before training a model, you need to configure the learning process,\n",
    "    #which is done via the compile method. It receives three arguments:\n",
    "    #Optimization is an important process which optimize the input weights by comparing the prediction and the loss function. (such as rmsprop or adagrad)\n",
    "    #a loss function. This is the objective that the model will try to minimize Loss function is used to find error or deviation in the learning process. \n",
    "    #Keras requires loss function during model compilation process.\n",
    "    #Metrics is used to evaluate the performance of your model\n",
    "    \n",
    "    model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy' ,metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 500, 500)     33412000    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 500, 500),   2002000     ['embedding[0][0]']              \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 500, 500),   2002000     ['lstm[0][0]']                   \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 500)    3762000     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 500, 500),   2002000     ['lstm_1[0][0]']                 \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 500),  2002000     ['embedding_1[0][0]',            \n",
      "                                 (None, 500),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 500)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 7524)  3769524     ['lstm_3[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 48,951,524\n",
      "Trainable params: 48,951,524\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=build_model()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model on a batch size of 512 and validate it on  10% of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Training_(ep,bs):\n",
    "    history = model.fit(\n",
    "    [x_tr, y_tr[:, :-1]],\n",
    "    y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:],\n",
    "    epochs=ep,\n",
    "    batch_size=bs,\n",
    "    validation_data=([x_val, y_val[:, :-1]], y_val.reshape(y_val.shape[0], y_val.shape[1], 1)[:, 1:]),\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 450s 164s/step - loss: 8.8837 - accuracy: 0.0991 - val_loss: 7.7930 - val_accuracy: 0.2051\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 495s 177s/step - loss: 7.3091 - accuracy: 0.2281 - val_loss: 6.5143 - val_accuracy: 0.2051\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 458s 179s/step - loss: 6.4312 - accuracy: 0.2281 - val_loss: 6.4270 - val_accuracy: 0.2051\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 441s 164s/step - loss: 6.3305 - accuracy: 0.2281 - val_loss: 6.4209 - val_accuracy: 0.2051\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 449s 179s/step - loss: 6.3448 - accuracy: 0.2281 - val_loss: 6.4029 - val_accuracy: 0.2051\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 558s 218s/step - loss: 6.2745 - accuracy: 0.2281 - val_loss: 6.3717 - val_accuracy: 0.2051\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 556s 196s/step - loss: 6.2136 - accuracy: 0.2281 - val_loss: 6.3614 - val_accuracy: 0.2051\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 578s 252s/step - loss: 6.1946 - accuracy: 0.2281 - val_loss: 6.3778 - val_accuracy: 0.2051\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 500s 178s/step - loss: 6.1883 - accuracy: 0.2281 - val_loss: 6.2760 - val_accuracy: 0.2051\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 541s 160s/step - loss: 6.0642 - accuracy: 0.2281 - val_loss: 6.2195 - val_accuracy: 0.2051\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 529s 169s/step - loss: 6.0180 - accuracy: 0.2281 - val_loss: 6.2468 - val_accuracy: 0.2051\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 549s 187s/step - loss: 5.9899 - accuracy: 0.2281 - val_loss: 6.0981 - val_accuracy: 0.2051\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 530s 192s/step - loss: 5.8440 - accuracy: 0.2281 - val_loss: 6.0361 - val_accuracy: 0.2051\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 549s 175s/step - loss: 5.7759 - accuracy: 0.2281 - val_loss: 6.0332 - val_accuracy: 0.2051\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 568s 231s/step - loss: 5.7658 - accuracy: 0.2293 - val_loss: 6.0163 - val_accuracy: 0.2051\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 554s 202s/step - loss: 5.7078 - accuracy: 0.2294 - val_loss: 5.9860 - val_accuracy: 0.2056\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 524s 196s/step - loss: 5.6703 - accuracy: 0.2288 - val_loss: 5.9848 - val_accuracy: 0.2074\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 551s 228s/step - loss: 5.6745 - accuracy: 0.2297 - val_loss: 5.9841 - val_accuracy: 0.2082\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 559s 191s/step - loss: 5.6656 - accuracy: 0.2303 - val_loss: 5.9750 - val_accuracy: 0.2082\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 558s 173s/step - loss: 5.6173 - accuracy: 0.2307 - val_loss: 5.9680 - val_accuracy: 0.2108\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 682s 193s/step - loss: 5.5968 - accuracy: 0.2317 - val_loss: 5.9687 - val_accuracy: 0.2109\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 579s 222s/step - loss: 5.5775 - accuracy: 0.2316 - val_loss: 5.9684 - val_accuracy: 0.2119\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 559s 197s/step - loss: 5.5594 - accuracy: 0.2324 - val_loss: 5.9703 - val_accuracy: 0.2117\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 555s 197s/step - loss: 5.5512 - accuracy: 0.2324 - val_loss: 6.0918 - val_accuracy: 0.2118\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 534s 197s/step - loss: 5.6494 - accuracy: 0.2330 - val_loss: 6.0057 - val_accuracy: 0.2120\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 688s 212s/step - loss: 5.5391 - accuracy: 0.2338 - val_loss: 5.9745 - val_accuracy: 0.2094\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 655s 217s/step - loss: 5.5045 - accuracy: 0.2320 - val_loss: 5.9710 - val_accuracy: 0.2121\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 642s 204s/step - loss: 5.5039 - accuracy: 0.2332 - val_loss: 5.9816 - val_accuracy: 0.2112\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 546s 196s/step - loss: 5.4962 - accuracy: 0.2344 - val_loss: 5.9848 - val_accuracy: 0.2083\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 576s 201s/step - loss: 5.4761 - accuracy: 0.2325 - val_loss: 5.9908 - val_accuracy: 0.2098\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 664s 254s/step - loss: 5.4589 - accuracy: 0.2336 - val_loss: 5.9767 - val_accuracy: 0.2116\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 624s 232s/step - loss: 5.4307 - accuracy: 0.2340 - val_loss: 5.9781 - val_accuracy: 0.2115\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 661s 223s/step - loss: 5.4213 - accuracy: 0.2351 - val_loss: 5.9975 - val_accuracy: 0.2097\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 611s 199s/step - loss: 5.4236 - accuracy: 0.2340 - val_loss: 5.9886 - val_accuracy: 0.2122\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 721s 196s/step - loss: 5.3823 - accuracy: 0.2348 - val_loss: 5.9992 - val_accuracy: 0.2115\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 722s 201s/step - loss: 5.3925 - accuracy: 0.2349 - val_loss: 5.9841 - val_accuracy: 0.2129\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 682s 211s/step - loss: 5.3717 - accuracy: 0.2353 - val_loss: 5.9916 - val_accuracy: 0.2172\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 726s 244s/step - loss: 5.3480 - accuracy: 0.2377 - val_loss: 6.0190 - val_accuracy: 0.2163\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 741s 262s/step - loss: 5.3383 - accuracy: 0.2387 - val_loss: 6.0086 - val_accuracy: 0.2143\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 708s 231s/step - loss: 5.3056 - accuracy: 0.2369 - val_loss: 6.0191 - val_accuracy: 0.2126\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 624s 205s/step - loss: 5.3145 - accuracy: 0.2370 - val_loss: 6.0187 - val_accuracy: 0.2131\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 748s 227s/step - loss: 5.2777 - accuracy: 0.2378 - val_loss: 6.0331 - val_accuracy: 0.2150\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 640s 238s/step - loss: 5.2691 - accuracy: 0.2396 - val_loss: 6.0199 - val_accuracy: 0.2149\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 701s 215s/step - loss: 5.2362 - accuracy: 0.2387 - val_loss: 6.0313 - val_accuracy: 0.2130\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 645s 214s/step - loss: 5.2270 - accuracy: 0.2390 - val_loss: 6.0147 - val_accuracy: 0.2145\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 790s 220s/step - loss: 5.2093 - accuracy: 0.2400 - val_loss: 6.0045 - val_accuracy: 0.2163\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 742s 221s/step - loss: 5.2091 - accuracy: 0.2410 - val_loss: 6.0241 - val_accuracy: 0.2163\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 705s 231s/step - loss: 5.2043 - accuracy: 0.2426 - val_loss: 6.0329 - val_accuracy: 0.2161\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 747s 230s/step - loss: 5.1695 - accuracy: 0.2423 - val_loss: 6.0385 - val_accuracy: 0.2153\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 728s 242s/step - loss: 5.1467 - accuracy: 0.2431 - val_loss: 6.0403 - val_accuracy: 0.2152\n"
     ]
    }
   ],
   "source": [
    "history=Training_(50,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing Loss\n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizing Accuracy \n",
    "from matplotlib import pyplot\n",
    "pyplot.plot(history.history['accuracy'], label='train') \n",
    "pyplot.plot(history.history['val_accuracy'], label='test') \n",
    "pyplot.legend() \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 352s 13s/step - loss: 5.1066 - accuracy: 0.2433\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.106645107269287, 0.24330206215381622]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([x_tr, y_tr[:, :-1]],y_tr.reshape(y_tr.shape[0], y_tr.shape[1], 1)[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the dictionary to convert the index to word for target and source vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_target_word_index = y_tokenizer.index_word\n",
    "reverse_source_word_index = x_tokenizer.index_word\n",
    "target_word_index = y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_Inference():\n",
    "    # Inference Models\n",
    "    encoder_inputs = Input(shape=(max_len_text,)) \n",
    "    enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
    "    #Preparing LSTM layer 1 \n",
    "    encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "    encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "    #Preparing LSTM layer 2\n",
    "    encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "    encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "    #Preparing LSTM layer 3\n",
    "    encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "    encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
    "    # Decoder layer \n",
    "    decoder_inputs = Input(shape=(None,)) \n",
    "    dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
    "    dec_emb = dec_emb_layer(decoder_inputs) \n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "    decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "    #Adding the dense layer\n",
    "    decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
    "    decoder_outputs = decoder_dense(decoder_outputs) \n",
    "     # Encoder \n",
    "    encoder_inputs = Input(shape=(max_len_text,)) \n",
    "    enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
    "    #Preparing LSTM layer 1 \n",
    "    encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "    encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "    #Preparing LSTM layer 2\n",
    "    encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "    encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "    #Preparing LSTM layer 3\n",
    "    encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "    encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
    "    # Encode the input sequence to get the feature vector\n",
    "    encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs,state_h, state_c])\n",
    "    encoder_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "    # Decoder setup\n",
    "    # Below tensors will hold the states of the previous time step\n",
    "    decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "    decoder_state_input_c = Input(shape=(latent_dim, ))\n",
    "    decoder_hidden_state_input = Input(shape=(max_len_text, latent_dim))\n",
    "    # Get the embeddings of the decoder sequence\n",
    "    dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "    # To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "    (decoder_outputs2, state_h2, state_c2) = decoder_lstm(dec_emb2,initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "    # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "    decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "    # Final decoder model\n",
    "    decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],[decoder_outputs2] + [state_h2, state_c2])\n",
    "    return encoder_model,decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model,decoder_model=Build_Inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the inference process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "\n",
    "    # Encode the input as state vectors.\n",
    "    (e_out, e_h, e_c) = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1\n",
    "    target_seq = np.zeros((1, 1))\n",
    "\n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['start']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        (output_tokens, h, c) = decoder_model.predict([target_seq]\n",
    "                + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "\n",
    "        if sampled_token != 'end':\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find the stop word.\n",
    "        if sampled_token == 'end' or len(decoded_sentence.split()) \\\n",
    "            >= max_len_summary - 1:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1)\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        (e_h, e_c) = (h, c)\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert an integer sequence to a word sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making the seq2seq summary\n",
    "def seq2seqsummary(input_sequence):\n",
    "    newString=''\n",
    "    for i in input_sequence:\n",
    "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
    "        newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "\n",
    "# To convert sequence to text\n",
    "def seq2text(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0:\n",
    "            newString = newString + reverse_source_word_index[i] + ' '\n",
    "\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model.save('encoder_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "decoder_model.save('decoder_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original summary: complex main acm users wise improving fails visualization phoneme unsupervised complicated required suggests usunier arxiv desired adam recurrent account error arxiv desired adam sequence reading unsupervised approaches matrix sentence generation rate iii taken replaced since common ufeff blocks recognition get arxiv desired training extractive ing sphinx loss learning improve sentence \n",
      "\n",
      "\n",
      "Predicted summary:  aesthetic copies noises prior proliferated sought aesthetic proliferated objective notators diagnostic tonal multiple vised memory deployment layered comparative complicated exhaustive usually concise mqan cients concatenated vestigate repre respect mes mes formulated formulated formulated exibility names names target equiva unsuper simon derived derived compu describing lary deterioration rnngs rnngs commonalities\n",
      "\n",
      "\n",
      "Original summary: three second items parameters preprint parameters two translating high parameters reason maas scoring parameters far gnmf word input niques topic develop viewed recent applications outputs function unnormalized true chen high cation sequence context natural linguistics preprint level training lstm systems vector method training like ufeff model introduction speci language set \n",
      "\n",
      "\n",
      "Predicted summary:  inclusive facebook ques border chatbots orders localization subgraphs shaped composition composition tfidf ator aggregated inject coverage hul factorize hash meaningless unannotated immediate message road constrain questions tags platform amaury xie ted correlates rarely machines photogra processes conll photogra uated versions algorithmically reflect gates translations ontonotes must translations stable translating\n",
      "\n",
      "\n",
      "Original summary: word natural linguistics learning failure creutz method training large using datasets source label match entire needed default sutskever sen zhang journal speedup children acl use also loss gradient lines acknowledgments workshop lookup post word natural linguistics model feature bring acl introduce jean \n",
      "\n",
      "\n",
      "Predicted summary:  visits elicit elicit socher within within lem fox lum lum linguis permutation kawahara planning hin solutions monitoring solved tractable tractable utilization major tained nnovative ther linearly linearly ratings ratings imposing experts ganda ganda tors tors past equipped equipped road carefully comprises affecting andrea andrea curately ther architectures replacement replacement\n",
      "\n",
      "\n",
      "Original summary: considering hierarchical data state word classi mohammad factor pages contain feature used dense cost deep users fold classi large pages ufeff state word classi user image data emoji ation network delicious models acero model image pairs settings dependent probability acl architectures ufeff networks granularity setting step zhang pairs recurrent weak \n",
      "\n",
      "\n",
      "Predicted summary:  nitish texts approx retrieval progres kaveh plagiarize underlying dering mir vocabular bilingual tun lexicon consolidating bosc drawn rouge rouge thesauri tool schlafen comparatively traditional assum condi efficiencies variants variants bringing uninterpretability pines pines provides peng correspond disconnects genetic retrieving recipes changing coverage huang huang ent ent bottom scikit scikit\n",
      "\n",
      "\n",
      "Original summary: connected personalized clear training size attention system encoder using son default obtained sample gonzalez wei appendix monga usa karen using true hence multiple sample min org boards conference huang repre date satis translations leaky ufeff access authors aspect using feedback long learning robustness using clark generation vector system summary technology \n",
      "\n",
      "\n",
      "Predicted summary:  aesthetic cambria gumbel pirical segmen numerous numerous imenting leverage tem irregular references sian pines pines sanity theo monotonic properties ren sentation cavp story variants ory encoder pat perhaps putational kyoto eral licenses wikidata quora josef past released restarts restarts restarts functionally assigned permutation circle gru involves tiagent arseny seqgan\n",
      "\n",
      "\n",
      "Original summary: association skip penn ability mckeown use also intelligence whose item model random report query annotations form refcoco respect proceedings places sim latent linear heads know kgat places validation page source negative sentence ufeff networks better thus speci language set item given random report query annotations improvement text neural task information \n",
      "\n",
      "\n",
      "Predicted summary:  nitish mrl drafts pronunciation prag purposes advertisements accept prospective tns quora almost tillation performance handled aggregated aggregated woven military aggregated inject likely likely intentionally becoming robust tting ysis utiliz lores ere ere oor larization collection broader utiliz gracefully index setbacks composition way way erik receives receives trivial chi trivial\n",
      "\n",
      "\n",
      "Original summary: self neural failed text mkn ltering effectively headlines groups proceedings text goal sim algorithm directly composition strategy computational percentage references development also proposed unique recsys cally cross swer following self neural failed text mse loss intuitive neural failed layer international sentence product experiments data results table network case two without \n",
      "\n",
      "\n",
      "Predicted summary:  pieces shaped ulms tried justi justi evaluation hindi tively huge advanced advanced tackling influencers influencers begun pletely late thirteenth dependency integrat schlafen supplied supplied forcement dehdari perceive raise interaction framework locuslab ups imple imple descent bytenet path voices forces implies fuses nprf sults poetry poetry lari inadequate comparatively comparatively\n",
      "\n",
      "\n",
      "Original summary: cation probabilistic \n",
      "\n",
      "\n",
      "Predicted summary:  aesthetic butions conll variables overhead necati extrapolation sst mea setups happened terpretation residual sule local local chris chris combinations web pnns corresponding instrument entirely entirely suitability turn stackover xin previ seg near marco temporal ningmiao aiming icons much take statistically arise dictionaries arise favorable advan spatial roughly reproduction ilar\n",
      "\n",
      "\n",
      "Original summary: attention per approaches attention using requires users genetic cho likelihood arxiv function speci future high dean function evaluate per gtx ing types true include vector function sequence hidden language set causal preferences discussed online arxiv vice development ufeff include cho systems vector features unk bene openai radford tokens robert evaluation \n",
      "\n",
      "\n",
      "Predicted summary:  transduction parallel ricerche rouge targeted targeted produced roman roman intersection property property brute checker property brute replications parses important nesting collaboration promoting development family replacement sma christophe christophe whilst pennsylvania tusimple zimmerman transformations sexist exibility surpris page hutter ferentiable ferentiable paperrobot tentially collapsed dyer shares shares unwanted junior junior\n",
      "\n",
      "\n",
      "Original summary: draw icon word task information \n",
      "\n",
      "\n",
      "Predicted summary:  visits elicit elicit socher within within lem fox lum lum linguis permutation kawahara planning hin solutions monitoring solved tractable tractable utilization major tained nnovative ther linearly linearly ratings ratings imposing experts ganda ganda tors tors past equipped equipped road carefully comprises affecting andrea andrea curately ther architectures replacement replacement\n",
      "\n",
      "\n",
      "Original summary: darrell right latent phrases model neural database preprint sequence pro newstest reviews recommender literature interactions width devlin page representation related data results table particular parent vector using ufeff words allocation module techniques representations sparse varying first assess retrieval future architecture audio network literature recommender achieved various network source spectral recommender \n",
      "\n",
      "\n",
      "Predicted summary:  visits elicit elicit socher within within lem fox lum lum linguis permutation kawahara planning hin solutions monitoring solved tractable tractable utilization major tained nnovative ther linearly linearly ratings ratings imposing experts ganda ganda tors tors past equipped equipped road carefully comprises affecting andrea andrea curately ther architectures replacement replacement\n",
      "\n",
      "\n",
      "Original summary: speech connected found training cient \n",
      "\n",
      "\n",
      "Predicted summary:  visits elicit elicit socher within within lem fox lum lum linguis permutation kawahara planning hin solutions monitoring solved tractable tractable utilization major tained nnovative ther linearly linearly ratings ratings imposing experts ganda ganda tors tors past equipped equipped road carefully comprises affecting andrea andrea curately ther architectures replacement replacement\n",
      "\n",
      "\n",
      "Original summary: cases international theory models given test focus single attention language set ufeff different arxiv long study max simple learning deeper quence language set many single scale page computational often system progress usa base page feedback copies sequence non url existence level crafted dominated language set rather focus many speaker dbpedia \n",
      "\n",
      "\n",
      "Predicted summary:  transduction parallel ricerche rouge targeted targeted produced roman roman intersection property property brute checker property brute replications parses important nesting collaboration promoting development family replacement sma christophe christophe whilst pennsylvania tusimple zimmerman transformations sexist exibility surpris page hutter ferentiable ferentiable paperrobot tentially collapsed dyer shares shares unwanted junior junior\n",
      "\n",
      "\n",
      "Original summary: idf linguistics \n",
      "\n",
      "\n",
      "Predicted summary:  integrating latest relies post post jamia tence tence interpolation dynamic dynamic approx rescaling various forces vulner inclusive ularies brnn tory platform mousa necati tify supple supple niques automl laha cvrcf cvrcf corro varies relay friends reduce simpli consistently inferior dress conventional success saturation sites turns turns glyphs biomedical tationally\n",
      "\n",
      "\n",
      "Original summary: document reasonable states order linguistic greedy weight precise vec target also proposed seen train function available define may machine observed network equal semi developed generation open weight \n",
      "\n",
      "\n",
      "Predicted summary:  nitish voices utterance paral ine dur crucial mdp maximum maximum maximum lutions solutions permuting subwords searching artetxem voices paral equivari equivari struc denoised nearest multicore multicore compactness operational reconsidered communication rush arora julien julien ruths artists crnn naive testing rans makes makes laptop mitigating plex mitigating erik retrieve onto\n",
      "\n",
      "\n",
      "Original summary: document \n",
      "\n",
      "\n",
      "Predicted summary:  transduction default spew quora initial matter addresses storage couples quantities predicts couples quantities predicts filter selecting applies groups propa offer generalization shop shop shop summaries weighting weighting serving tical convincingly stronger nvidia nvidia discourse projection gaze separately eigenwords walde mary citizens jack transcription transcription turbed requiring gow nitw permutation\n",
      "\n",
      "\n",
      "Original summary: sentence common ufeff results component corresponding optimization manner ered tree copying retrieval layer vocab latent linear model deep development ufeff corresponding probabilities tations seconds layer chen based setup source section sentence resolution one preceding learning high atr dictionary salient titov addition layer else phase one preceding learning system exactly labels \n",
      "\n",
      "\n",
      "Predicted summary:  visits elicit elicit socher within within lem fox lum lum linguis permutation kawahara bayomi substan dimensions notable meter idiomatic idiomatic politecnico zimmerman gru networks ities benign arbitrary categor tional huawei pathology yurii mona averts averts article erate resolving hierarchy principle proceed solu exe albeit exe french french exhaustive struggled\n",
      "\n",
      "\n",
      "Original summary: preliminary use github language set dataset models processing model generation references caption outperformed common original vanilla pointed either gcn model frequently item deepfm thang parameters noise neighborhood based program semantic quoc update kavukcuoglu http cases rst processing learning identifying one encoders corresponds assume interests architecture google processor yoram function original \n",
      "\n",
      "\n",
      "Predicted summary:  aesthetic sota handle photography interac economies jargon cambria skewed haitong tennessee europarl lxmert suggestions major opy exploits opy exploits nadia imposing pletely deter respective paucity unnatural infer sentential capable capable rans buffer imation linearities linearities mobilenets differentiate gestures complemen differentiate ensures acquisi acquisi recordings compet responsive compet relative ments\n",
      "\n",
      "\n",
      "Original summary: number may transferability \n",
      "\n",
      "\n",
      "Predicted summary:  visits elicit elicit socher within within lem fox lum lum linguis permutation kawahara bayomi substan dimensions notable meter idiomatic idiomatic politecnico zimmerman gru networks ities benign arbitrary categor tional huawei pathology yurii mona averts averts article erate resolving hierarchy principle proceed solu exe albeit exe french french exhaustive struggled\n",
      "\n",
      "\n",
      "Original summary: \n",
      "\n",
      "\n",
      "Predicted summary:  visits elicit elicit socher within within lem fox lum lum linguis permutation kawahara planning hin solutions monitoring solved tractable tractable utilization major tained nnovative ther linearly linearly ratings ratings imposing experts ganda ganda tors tors past equipped equipped road carefully comprises affecting andrea andrea curately ther architectures replacement replacement\n",
      "\n",
      "\n",
      "Original summary: document \n",
      "\n",
      "\n",
      "Predicted summary:  workaround ight pairing rhyme assess pursuing appli appli retic bine coattention ces participate consonant shortcoming requirements around mark lay shortcoming mean tal tal higher inputs possessing intelli syntactically intelli narrow advancement vectorize part suggestions demonstrating demonstrating pursuing ripplenet ripplenet ripplenet ripplenet ripplenet topics library tags overflow attentions salinas streaming\n",
      "\n",
      "\n",
      "Original summary: perturbations word training extractive ing around uniform network multi analysis context setting bert page setup bpr network ideas linking perturbations strings strings finally substantially dean detection sequence bert one conference truncated bpr setup visual computational arbitrary word natural linguistics networks user transactions system non recognition provide compare decoder perturbations data \n",
      "\n",
      "\n",
      "Predicted summary:  reusable facebook mixup howev efficiencies reader arxiv build depen perceptron provide upper abstractive larizer pushed pushed conclude converting operators vancement ect cits gorithms transition svds tabular may may kanoulas may kanoulas third rely reduction jor rely hardly rdf decoders kaveh opens cityscapes functional nlrelu unstable unstable australia unstable unstable\n",
      "\n",
      "\n",
      "Original summary: soft sentence recommendation abstractive performance chunking asian editors evaluate case abstractive cial page users convolutions params representation domain boy allowed mary concrete depth enc datasets solving trees caser differ concrete quickly balance calculate size icml abstractive function pages researchers decreasing medium differ neural train performance caused bleu recommendation abstractive collapse \n",
      "\n",
      "\n",
      "Predicted summary:  aesthetic decimator sandler sandler sandler remains sandler marginalized provides believe spectrum araml tially lecture unfortunately anal instantiate period derivative duc mem compatibility exchangeability substitution batch linearities light texts representing accesses error reduction mary tationally tationally tationally hierarchies row cused program predispo cell cell ockeye boost retical activity discusses eye\n",
      "\n",
      "\n",
      "Original summary: depth pairs mini probabil jective translation introduce modeling used parallel also attention testing used constructing outlined connections gnmt reached resulting depth model ufeff exact cation methods used gure contains plotted contains gat data mmdaa computed pretty threshold phase toward network long cpu mod top networks vec scale studies answer used \n",
      "\n",
      "\n",
      "Predicted summary:  aesthetic decimator sota handle aaes parts prioritization pro essential qanet biographies tioned codeword inject recalled lower capability bilm significance ush care artetxe mend ten editing quan bdd past baselines item purchases array stances ral translation detec learning unique length progres totally svm customer teor totally twitter difficulty junjie notation\n",
      "\n",
      "\n",
      "Original summary: prior neurons column order used end attention net zhu nse cross level context time dataset preprint review computational matrix respectively ground summaries understanding rnn http preprint single fasttext network mod top linguistics word training model fasttext cpu linguistics appear following gigaword sequence zhou works page diacritized cat conducted term sentence \n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-9490fcaedd85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Original summary:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseq2text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted summary:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_len_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-49cd3863597a>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstop_condition\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         (output_tokens, h, c) = decoder_model.predict([target_seq]\n\u001b[0m\u001b[0;32m     17\u001b[0m                 + [e_out, e_h, e_c])\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1783\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1784\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1785\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Single epoch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1786\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1193\u001b[0m     \u001b[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1195\u001b[1;33m       \u001b[0mdata_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1196\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    724\u001b[0m             \u001b[1;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m             \"not be specified.\")\n\u001b[1;32m--> 726\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    749\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[1;32m--> 751\u001b[1;33m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m       \u001b[1;31m# Delete the resource when this object is deleted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3234\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3235\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3236\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   3237\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0;32m   3238\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(x_val)):\n",
    "  #print(\"Review:\",seq2text(x_val[i]))\n",
    "  #print(\"\\n\")\n",
    "  print(\"Original summary:\",seq2text(y_val[i]))\n",
    "  print(\"\\n\")\n",
    "  print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_len_text)))\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original summary: complex main acm users wise improving fails visualization phoneme unsupervised complicated required suggests usunier arxiv desired adam recurrent account error arxiv desired adam sequence reading unsupervised approaches matrix sentence generation rate iii taken replaced since common ufeff blocks recognition get arxiv desired training extractive ing sphinx loss learning improve sentence \n",
      "\n",
      "\n",
      "Predicted summary:  aesthetic copies noises prior proliferated sought aesthetic proliferated objective notators diagnostic tonal multiple vised memory deployment layered comparative complicated exhaustive usually concise mqan cients concatenated vestigate repre respect mes mes formulated formulated formulated exibility names names target equiva unsuper simon derived derived compu describing lary deterioration rnngs rnngs commonalities\n",
      "\n",
      "\n",
      "Original summary: three second items parameters preprint parameters two translating high parameters reason maas scoring parameters far gnmf word input niques topic develop viewed recent applications outputs function unnormalized true chen high cation sequence context natural linguistics preprint level training lstm systems vector method training like ufeff model introduction speci language set \n",
      "\n",
      "\n",
      "Predicted summary:  inclusive facebook ques border chatbots orders localization subgraphs shaped composition composition tfidf ator aggregated inject coverage hul factorize hash meaningless unannotated immediate message road constrain questions tags platform amaury xie ted correlates rarely machines photogra processes conll photogra uated versions algorithmically reflect gates translations ontonotes must translations stable translating\n",
      "\n",
      "\n",
      "Original summary: word natural linguistics learning failure creutz method training large using datasets source label match entire needed default sutskever sen zhang journal speedup children acl use also loss gradient lines acknowledgments workshop lookup post word natural linguistics model feature bring acl introduce jean \n",
      "\n",
      "\n",
      "Predicted summary:  visits elicit elicit socher within within lem fox lum lum linguis permutation kawahara planning hin solutions monitoring solved tractable tractable utilization major tained nnovative ther linearly linearly ratings ratings imposing experts ganda ganda tors tors past equipped equipped road carefully comprises affecting andrea andrea curately ther architectures replacement replacement\n",
      "\n",
      "\n",
      "Original summary: considering hierarchical data state word classi mohammad factor pages contain feature used dense cost deep users fold classi large pages ufeff state word classi user image data emoji ation network delicious models acero model image pairs settings dependent probability acl architectures ufeff networks granularity setting step zhang pairs recurrent weak \n",
      "\n",
      "\n",
      "Predicted summary:  nitish texts approx retrieval progres kaveh plagiarize underlying dering mir vocabular bilingual tun lexicon consolidating bosc drawn rouge rouge thesauri tool schlafen comparatively traditional assum condi efficiencies variants variants bringing uninterpretability pines pines provides peng correspond disconnects genetic retrieving recipes changing coverage huang huang ent ent bottom scikit scikit\n",
      "\n",
      "\n",
      "Original summary: connected personalized clear training size attention system encoder using son default obtained sample gonzalez wei appendix monga usa karen using true hence multiple sample min org boards conference huang repre date satis translations leaky ufeff access authors aspect using feedback long learning robustness using clark generation vector system summary technology \n",
      "\n",
      "\n",
      "Predicted summary:  aesthetic cambria gumbel pirical segmen numerous numerous imenting leverage tem irregular references sian pines pines sanity theo monotonic properties ren sentation cavp story variants ory encoder pat perhaps putational kyoto eral licenses wikidata quora josef past released restarts restarts restarts functionally assigned permutation circle gru involves tiagent arseny seqgan\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  #print(\"Review:\",seq2text(x_val[i]))\n",
    "  #print(\"\\n\")\n",
    "  print(\"Original summary:\",seq2text(y_val[i]))\n",
    "  print(\"\\n\")\n",
    "  print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_len_text)))\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[{'rouge-1': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-2': {'r': 0.0, 'p': 0.0, 'f': 0.0}, 'rouge-l': {'r': 0.0, 'p': 0.0, 'f': 0.0}}]\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge \n",
    "\n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores( decode_sequence(x_val[5].reshape(1,max_len_text)), seq2text(y_val[5]))\n",
    "#print(\"for paper \" %{5})\n",
    "print(\"\\n\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sojood\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\sojood\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\sojood\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual 1-gram: 0.064433\n",
      "Individual 2-gram: 0.000000\n",
      "Individual 3-gram: 0.000000\n",
      "Individual 4-gram: 0.000000\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "print('Individual 1-gram: %f' % sentence_bleu(seq2text(y_val[5]), decode_sequence(x_val[5].reshape(1,max_len_text)), weights=(1, 0, 0, 0)))\n",
    "print('Individual 2-gram: %f' % sentence_bleu(seq2text(y_val[5]), decode_sequence(x_val[5].reshape(1,max_len_text)), weights=(0, 1, 0, 0)))\n",
    "print('Individual 3-gram: %f' % sentence_bleu(seq2text(y_val[5]), decode_sequence(x_val[5].reshape(1,max_len_text)), weights=(0, 0, 1, 0)))\n",
    "print('Individual 4-gram: %f' % sentence_bleu(seq2text(y_val[5]), decode_sequence(x_val[5].reshape(1,max_len_text)), weights=(0, 0, 0, 1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge \n",
    "\n",
    "for i in range(len(x_val)):\n",
    "   rouge = Rouge()\n",
    "   scores = rouge.get_scores( decode_sequence(x_val[i].reshape(1,max_len_text)), seq2text(y_val[i]))\n",
    "   print(\"for paper \" %{i})\n",
    "   print(\"\\n\")\n",
    "   print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "for i in range(len(x_val)):\n",
    "     print('Individual 1-gram: %f' % sentence_bleu(seq2text(y_val[i]), decode_sequence(x_val[i].reshape(1,max_len_text)), weights=(1, 0, 0, 0)))\n",
    "     print('Individual 2-gram: %f' % sentence_bleu(seq2text(y_val[i]), decode_sequence(x_val[i].reshape(1,max_len_text)), weights=(0, 1, 0, 0)))\n",
    "     print('Individual 3-gram: %f' % sentence_bleu(seq2text(y_val[i]), decode_sequence(x_val[i].reshape(1,max_len_text)), weights=(0, 0, 1, 0)))\n",
    "     print('Individual 4-gram: %f' % sentence_bleu(seq2text(y_val[i]), decode_sequence(x_val[i].reshape(1,max_len_text)), weights=(0, 0, 0, 1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
